listVec <- lapply(results, c, recursive=TRUE)
x <- do.call(cbind, listVec)
#if you want, plot a histogram of a row of x of interest
#this is row 15: the x-->t transition
hist(x[15,])
#the observed RM dataset has 44 x-->t transitions.
abline(v=44)
#calculate 5% and 95% quantile for permuted data
#Green & Patek 2017 uses only the 95% quantile, but the 5% may be useful if interested in which behaviours occurred less frequently than expected.
quantiles<-matrix(NA,nrow=nrow(x),ncol=2)
for (i in 1:nrow(x)){
q<-quantile(x[i,],probs=c(0.05,0.95))
quantiles[i,]<-q
}
#check structure of quantiles
head(quantiles)
str(quantiles)
#save matrices for each of the low and high quantile data
low<-matrix(quantiles[,1],nrow=14,byrow=F)
high<-matrix(quantiles[,2],nrow=14,byrow=F)
#rename the low and high quantile datasets to match the observed adjacency matrix
colnames(low)<-colnames(adjacency.matrix)
rownames(low)<-colnames(adjacency.matrix)
colnames(high)<-colnames(adjacency.matrix)
rownames(high)<-colnames(adjacency.matrix)
#inspect low, high, and observed matrices
low
high
adjacency.matrix
#save the low and high quantile datasets
write.csv(low,file='low_quantiles.csv')
write.csv(high,file='high_quantiles.csv')
#save the observed adjacency matrix
write.csv(adjacency.matrix,file='observed.csv')
##########################################################################
#### calculating transitional probabilities from the observed dataset ####
##########################################################################
#pull out the transitional probability values from the observed matrix
#divide each cell by the row sum
trans.prob<-round(adjacency.matrix/rowSums(adjacency.matrix),2)
trans.prob[is.nan(trans.prob)]<-0 #replace any NaN values with 0
trans.prob
#simplify the dataset to keep only those cell values where adjacency matrix is greater or equal to high quantile
#keep the original transitional probabilities, i.e. before simplification
keep<-ifelse(adjacency.matrix>=high,trans.prob,0)
#inspect the "keep" matrix
keep
#save the transitonal probability dataset
write.csv(trans.prob,file='transitional_probability.csv')
##################################################
#### visualising the transitions using igraph ####
##################################################
#create a network object from the significant transitional probability matrix (transitions more frequent than expected)
network<-graph.adjacency(keep,weighted=TRUE,diag=TRUE)
##########################################################################
#### calculating transitional probabilities from the observed dataset ####
##########################################################################
#pull out the transitional probability values from the observed matrix
#divide each cell by the row sum
trans.prob<-round(adjacency.matrix/rowSums(adjacency.matrix),2)
trans.prob[is.nan(trans.prob)]<-0 #replace any NaN values with 0
trans.prob
#simplify the dataset to keep only those cell values where adjacency matrix is greater or equal to high quantile
#keep the original transitional probabilities, i.e. before simplification
keep<-ifelse(adjacency.matrix>=high,trans.prob,0)
#Load required packages
library('sand')
library('igraph')
library('sna')
library('diagram')
#load data
data<-read.csv('Data group2.csv',header=F)
#inspect data
head(data)
#remove the first row (column descriptors) and the last two columns (contest descriptors)
data<-data[-c(1),-c(3,4)]
#generate the observed adjacency matrix
graph<-graph.data.frame(data,directed = T)
adjacency.matrix<-get.adjacency(graph,sparse=F)
#check that this is a 14x14 matrix for Green & Patek 2017
#if using your own data, the matrix should be n x n for an ethogram with n possible behaviours
adjacency.matrix
#permutation test
#define the number of permutations and create an empty list array to be filled
m<-10000
results<-as.list(NA)
#the loop below resamples the second column of the dataset w/o replacement to permute it.
#each iteration is saved as a matix in a list object (results[[i]])
for (i in 1:m){
perm<-data
perm[,2]<-perm[sample(1:nrow(perm),replace=FALSE),2]
perm.graph<-graph.data.frame(perm,directed = T)
perm.adjacency.matrix<-get.adjacency(perm.graph,sparse=F)
results[[i]]<-perm.adjacency.matrix
}
#inspect one sample from results; it should look like a 14x14 adjacency matrix
results[[3456]]
#reorganize list structure of results
listVec <- lapply(results, c, recursive=TRUE)
x <- do.call(cbind, listVec)
#if you want, plot a histogram of a row of x of interest
#this is row 15: the x-->t transition
hist(x[15,])
#the observed RM dataset has 44 x-->t transitions.
abline(v=44)
#calculate 5% and 95% quantile for permuted data
#Green & Patek 2017 uses only the 95% quantile, but the 5% may be useful if interested in which behaviours occurred less frequently than expected.
quantiles<-matrix(NA,nrow=nrow(x),ncol=2)
for (i in 1:nrow(x)){
q<-quantile(x[i,],probs=c(0.05,0.95))
quantiles[i,]<-q
}
#check structure of quantiles
head(quantiles)
str(quantiles)
#save matrices for each of the low and high quantile data
low<-matrix(quantiles[,1],nrow=14,byrow=F)
high<-matrix(quantiles[,2],nrow=14,byrow=F)
#rename the low and high quantile datasets to match the observed adjacency matrix
colnames(low)<-colnames(adjacency.matrix)
#Load required packages
library('sand')
function (..., list = character(), package = NULL, lib.loc = NULL,
verbose = getOption("verbose"), envir = .GlobalEnv, overwrite = TRUE)
{
fileExt <- function(x) {
db <- grepl("\\.[^.]+\\.(gz|bz2|xz)$", x)
ans <- sub(".*\\.", "", x)
ans[db] <- sub(".*\\.([^.]+\\.)(gz|bz2|xz)$", "\\1\\2",
x[db])
ans
}
my_read_table <- function(...) {
lcc <- Sys.getlocale("LC_COLLATE")
on.exit(Sys.setlocale("LC_COLLATE", lcc))
Sys.setlocale("LC_COLLATE", "C")
read.table(...)
}
stopifnot(is.character(list))
names <- c(as.character(substitute(list(...))[-1L]), list)
if (!is.null(package)) {
if (!is.character(package))
stop("'package' must be a character vector or NULL")
}
paths <- find.package(package, lib.loc, verbose = verbose)
if (is.null(lib.loc))
paths <- c(path.package(package, TRUE), if (!length(package)) getwd(),
paths)
paths <- unique(normalizePath(paths[file.exists(paths)]))
paths <- paths[dir.exists(file.path(paths, "data"))]
dataExts <- tools:::.make_file_exts("data")
if (length(names) == 0L) {
db <- matrix(character(), nrow = 0L, ncol = 4L)
for (path in paths) {
entries <- NULL
packageName <- if (file_test("-f", file.path(path,
"DESCRIPTION")))
basename(path)
else "."
if (file_test("-f", INDEX <- file.path(path, "Meta",
"data.rds"))) {
entries <- readRDS(INDEX)
}
else {
dataDir <- file.path(path, "data")
entries <- tools::list_files_with_type(dataDir,
"data")
if (length(entries)) {
entries <- unique(tools::file_path_sans_ext(basename(entries)))
entries <- cbind(entries, "")
}
}
if (NROW(entries)) {
if (is.matrix(entries) && ncol(entries) == 2L)
db <- rbind(db, cbind(packageName, dirname(path),
entries))
else warning(gettextf("data index for package %s is invalid and will be ignored",
sQuote(packageName)), domain = NA, call. = FALSE)
}
}
colnames(db) <- c("Package", "LibPath", "Item", "Title")
footer <- if (missing(package))
paste0("Use ", sQuote(paste("data(package =", ".packages(all.available = TRUE))")),
"\n", "to list the data sets in all *available* packages.")
else NULL
y <- list(title = "Data sets", header = NULL, results = db,
footer = footer)
class(y) <- "packageIQR"
return(y)
}
paths <- file.path(paths, "data")
for (name in names) {
found <- FALSE
for (p in paths) {
tmp_env <- if (overwrite)
envir
else new.env()
if (file_test("-f", file.path(p, "Rdata.rds"))) {
rds <- readRDS(file.path(p, "Rdata.rds"))
if (name %in% names(rds)) {
found <- TRUE
if (verbose)
message(sprintf("name=%s:\t found in Rdata.rds",
name), domain = NA)
thispkg <- sub(".*/([^/]*)/data$", "\\1",
p)
thispkg <- sub("_.*$", "", thispkg)
thispkg <- paste0("package:", thispkg)
objs <- rds[[name]]
lazyLoad(file.path(p, "Rdata"), envir = tmp_env,
filter = function(x) x %in% objs)
break
}
else if (verbose)
message(sprintf("name=%s:\t NOT found in names() of Rdata.rds, i.e.,\n\t%s\n",
name, paste(names(rds), collapse = ",")),
domain = NA)
}
if (file_test("-f", file.path(p, "Rdata.zip"))) {
warning("zipped data found for package ", sQuote(basename(dirname(p))),
".\nThat is defunct, so please re-install the package.",
domain = NA)
if (file_test("-f", fp <- file.path(p, "filelist")))
files <- file.path(p, scan(fp, what = "",
quiet = TRUE))
else {
warning(gettextf("file 'filelist' is missing for directory %s",
sQuote(p)), domain = NA)
next
}
}
else {
files <- list.files(p, full.names = TRUE)
}
files <- files[grep(name, files, fixed = TRUE)]
if (length(files) > 1L) {
o <- match(fileExt(files), dataExts, nomatch = 100L)
paths0 <- dirname(files)
paths0 <- factor(paths0, levels = unique(paths0))
files <- files[order(paths0, o)]
}
if (length(files)) {
for (file in files) {
if (verbose)
message("name=", name, ":\t file= ...",
.Platform$file.sep, basename(file), "::\t",
appendLF = FALSE, domain = NA)
ext <- fileExt(file)
if (basename(file) != paste0(name, ".", ext))
found <- FALSE
else {
found <- TRUE
zfile <- file
zipname <- file.path(dirname(file), "Rdata.zip")
if (file.exists(zipname)) {
Rdatadir <- tempfile("Rdata")
dir.create(Rdatadir, showWarnings = FALSE)
topic <- basename(file)
rc <- .External(C_unzip, zipname, topic,
Rdatadir, FALSE, TRUE, FALSE, FALSE)
if (rc == 0L)
zfile <- file.path(Rdatadir, topic)
}
if (zfile != file)
on.exit(unlink(zfile))
switch(ext, R = , r = {
library("utils")
sys.source(zfile, chdir = TRUE, envir = tmp_env)
}, RData = , rdata = , rda = load(zfile,
envir = tmp_env), TXT = , txt = , tab = ,
tab.gz = , tab.bz2 = , tab.xz = , txt.gz = ,
txt.bz2 = , txt.xz = assign(name, my_read_table(zfile,
header = TRUE, as.is = FALSE), envir = tmp_env),
CSV = , csv = , csv.gz = , csv.bz2 = ,
csv.xz = assign(name, my_read_table(zfile,
header = TRUE, sep = ";", as.is = FALSE),
envir = tmp_env), found <- FALSE)
}
if (found)
break
}
if (verbose)
message(if (!found)
"*NOT* ", "found", domain = NA)
}
if (found)
break
}
if (!found) {
warning(gettextf("data set %s not found", sQuote(name)),
domain = NA)
}
else if (!overwrite) {
for (o in ls(envir = tmp_env, all.names = TRUE)) {
if (exists(o, envir = envir, inherits = FALSE))
warning(gettextf("an object named %s already exists and will not be overwritten",
sQuote(o)))
else assign(o, get(o, envir = tmp_env, inherits = FALSE),
envir = envir)
}
rm(tmp_env)
}
}
invisible(names)
}
library('igraph')
library('sna')
library('diagram')
#load data
data<-read.csv('Data group2.csv',header=F)
#inspect data
head(data)
#remove the first row (column descriptors) and the last two columns (contest descriptors)
data<-data[-c(1),-c(3,4)]
#generate the observed adjacency matrix
graph<-graph.data.frame(data,directed = T)
adjacency.matrix<-get.adjacency(graph,sparse=F)
#check that this is a 14x14 matrix for Green & Patek 2017
#if using your own data, the matrix should be n x n for an ethogram with n possible behaviours
adjacency.matrix
#permutation test
#define the number of permutations and create an empty list array to be filled
m<-10000
results<-as.list(NA)
#the loop below resamples the second column of the dataset w/o replacement to permute it.
#each iteration is saved as a matix in a list object (results[[i]])
for (i in 1:m){
perm<-data
perm[,2]<-perm[sample(1:nrow(perm),replace=FALSE),2]
perm.graph<-graph.data.frame(perm,directed = T)
perm.adjacency.matrix<-get.adjacency(perm.graph,sparse=F)
results[[i]]<-perm.adjacency.matrix
}
#inspect one sample from results; it should look like a 14x14 adjacency matrix
results[[3456]]
#reorganize list structure of results
listVec <- lapply(results, c, recursive=TRUE)
x <- do.call(cbind, listVec)
#if you want, plot a histogram of a row of x of interest
#this is row 15: the x-->t transition
hist(x[15,])
#the observed RM dataset has 44 x-->t transitions.
abline(v=44)
#calculate 5% and 95% quantile for permuted data
#Green & Patek 2017 uses only the 95% quantile, but the 5% may be useful if interested in which behaviours occurred less frequently than expected.
quantiles<-matrix(NA,nrow=nrow(x),ncol=2)
for (i in 1:nrow(x)){
q<-quantile(x[i,],probs=c(0.05,0.95))
quantiles[i,]<-q
}
#check structure of quantiles
head(quantiles)
str(quantiles)
#save matrices for each of the low and high quantile data
low<-matrix(quantiles[,1],nrow=14,byrow=F)
high<-matrix(quantiles[,2],nrow=14,byrow=F)
#rename the low and high quantile datasets to match the observed adjacency matrix
colnames(low)<-colnames(adjacency.matrix)
rownames(low)<-colnames(adjacency.matrix)
colnames(high)<-colnames(adjacency.matrix)
rownames(high)<-colnames(adjacency.matrix)
#inspect low, high, and observed matrices
low
high
adjacency.matrix
#save the low and high quantile datasets
write.csv(low,file='low_quantiles.csv')
write.csv(high,file='high_quantiles.csv')
#save the observed adjacency matrix
write.csv(adjacency.matrix,file='observed.csv')
##########################################################################
#### calculating transitional probabilities from the observed dataset ####
##########################################################################
#pull out the transitional probability values from the observed matrix
#divide each cell by the row sum
trans.prob<-round(adjacency.matrix/rowSums(adjacency.matrix),2)
trans.prob[is.nan(trans.prob)]<-0 #replace any NaN values with 0
trans.prob
#simplify the dataset to keep only those cell values where adjacency matrix is greater or equal to high quantile
#keep the original transitional probabilities, i.e. before simplification
keep<-ifelse(adjacency.matrix>=high,trans.prob,0)
high
#Load required packages
library('sand')
#Load required packages
library('sand')
library('igraph')
library('sna')
library('diagram')
#load data
data<-read.csv('Data group2.csv',header=F)
#inspect data
head(data)
#remove the first row (column descriptors) and the last two columns (contest descriptors)
data<-data[-c(1),-c(3,4)]
#generate the observed adjacency matrix
graph<-graph.data.frame(data,directed = T)
adjacency.matrix<-get.adjacency(graph,sparse=F)
#check that this is a 14x14 matrix for Green & Patek 2017
#if using your own data, the matrix should be n x n for an ethogram with n possible behaviours
adjacency.matrix
#permutation test
#define the number of permutations and create an empty list array to be filled
m<-10000
results<-as.list(NA)
#the loop below resamples the second column of the dataset w/o replacement to permute it.
#each iteration is saved as a matix in a list object (results[[i]])
for (i in 1:m){
perm<-data
perm[,2]<-perm[sample(1:nrow(perm),replace=FALSE),2]
perm.graph<-graph.data.frame(perm,directed = T)
perm.adjacency.matrix<-get.adjacency(perm.graph,sparse=F)
results[[i]]<-perm.adjacency.matrix
}
#inspect one sample from results; it should look like a 14x14 adjacency matrix
results[[3456]]
View(results)
#load data
data<-read.csv('Data group1.csv',header=F)
#inspect data
head(data)
#remove the first row (column descriptors) and the last two columns (contest descriptors)
data<-data[-c(1),-c(3,4)]
#generate the observed adjacency matrix
graph<-graph.data.frame(data,directed = T)
adjacency.matrix<-get.adjacency(graph,sparse=F)
#check that this is a 14x14 matrix for Green & Patek 2017
#if using your own data, the matrix should be n x n for an ethogram with n possible behaviours
adjacency.matrix
#permutation test
#define the number of permutations and create an empty list array to be filled
m<-10000
results<-as.list(NA)
#the loop below resamples the second column of the dataset w/o replacement to permute it.
#each iteration is saved as a matix in a list object (results[[i]])
for (i in 1:m){
perm<-data
perm[,2]<-perm[sample(1:nrow(perm),replace=FALSE),2]
perm.graph<-graph.data.frame(perm,directed = T)
perm.adjacency.matrix<-get.adjacency(perm.graph,sparse=F)
results[[i]]<-perm.adjacency.matrix
}
#inspect one sample from results; it should look like a 14x14 adjacency matrix
results[[3456]]
#reorganize list structure of results
listVec <- lapply(results, c, recursive=TRUE)
x <- do.call(cbind, listVec)
#if you want, plot a histogram of a row of x of interest
#this is row 15: the x-->t transition
hist(x[15,])
#the observed RM dataset has 44 x-->t transitions.
abline(v=44)
#calculate 5% and 95% quantile for permuted data
#Green & Patek 2017 uses only the 95% quantile, but the 5% may be useful if interested in which behaviours occurred less frequently than expected.
quantiles<-matrix(NA,nrow=nrow(x),ncol=2)
for (i in 1:nrow(x)){
q<-quantile(x[i,],probs=c(0.05,0.95))
quantiles[i,]<-q
}
#check structure of quantiles
head(quantiles)
str(quantiles)
#save matrices for each of the low and high quantile data
low<-matrix(quantiles[,1],nrow=14,byrow=F)
high<-matrix(quantiles[,2],nrow=14,byrow=F)
#rename the low and high quantile datasets to match the observed adjacency matrix
colnames(low)<-colnames(adjacency.matrix)
rownames(low)<-colnames(adjacency.matrix)
colnames(high)<-colnames(adjacency.matrix)
rownames(high)<-colnames(adjacency.matrix)
#inspect low, high, and observed matrices
low
high
adjacency.matrix
#save the low and high quantile datasets
write.csv(low,file='low_quantiles.csv')
write.csv(high,file='high_quantiles.csv')
#save the observed adjacency matrix
write.csv(adjacency.matrix,file='observed.csv')
##########################################################################
#### calculating transitional probabilities from the observed dataset ####
##########################################################################
#pull out the transitional probability values from the observed matrix
#divide each cell by the row sum
trans.prob<-round(adjacency.matrix/rowSums(adjacency.matrix),2)
trans.prob[is.nan(trans.prob)]<-0 #replace any NaN values with 0
trans.prob
#simplify the dataset to keep only those cell values where adjacency matrix is greater or equal to high quantile
#keep the original transitional probabilities, i.e. before simplification
keep<-ifelse(adjacency.matrix>=high,trans.prob,0)
#inspect the "keep" matrix
keep
#save the transitonal probability dataset
write.csv(trans.prob,file='transitional_probability.csv')
##################################################
#### visualising the transitions using igraph ####
##################################################
#create a network object from the significant transitional probability matrix (transitions more frequent than expected)
network<-graph.adjacency(keep,weighted=TRUE,diag=TRUE)
#set vertex (circle) sizes to be equal to scaled degree of adjacency matrix
vertex_sizes<-degree(adjacency.matrix,rescale=TRUE)
#set edge (arrow) weights to be equal to 5 categories of edge weight (# of transitions)
edge_weights<-as.numeric(cut(E(network)$weight,c(0,.1,.25,.5,.75,1),labels=c(1:5)))
#plot the network - will open another window
#tkplot may not work with a Mac, but there may be other options available.
plot<-tkplot(network)
#move the vertices around to make an organized figure
#save the coordinates from this plot
#you can also load coordinates for each vertex as a matrix with n rows (one for each vertex) and 2 columns with x (col 1) and y (col 2) position
coords<-tkplot.getcoords(plot)
#finally, create a network plot using the above coordinates and weights.
plot.igraph(network,vertex.label=V(network)$name, vertex.label.cex = 1.25, layout=coords,vertex.size=vertex_sizes*150, edge.width=edge_weights/4, edge.arrow.size=edge_weights/4)
